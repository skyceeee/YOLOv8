{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# PC Webcam'ini başlat\n",
    "pc_kamera = cv2.VideoCapture(0)\n",
    "pc_kamera.set(3, 640)\n",
    "pc_kamera.set(4, 480)\n",
    "\n",
    "# Telefon kamerasını başlat\n",
    "telefon_kamera_adresi = \"http://172.16.3.109:8080/video\"  # Telefonunuzun IP Webcam uygulamasının sağladığı adresi kullanın\n",
    "telefon_kamera = cv2.VideoCapture(telefon_kamera_adresi)\n",
    "\n",
    "# YOLO modelini başlat\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "# Nesne sınıfları\n",
    "sinif_isimleri = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"]  # Sınıf isimleriniz\n",
    "\n",
    "while True:\n",
    "    # PC Webcam'inden görüntü al\n",
    "    pc_basari, pc_resim = pc_kamera.read()\n",
    "    pc_sonuclar = model(pc_resim, stream=True)\n",
    "\n",
    "    for r in pc_sonuclar:\n",
    "        pc_kutular = r.boxes\n",
    "\n",
    "        for pc_kutu in pc_kutular:\n",
    "            x1, y1, x2, y2 = pc_kutu.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Algılanan nesnenin sınırlayıcı kutusunu çiz\n",
    "            cv2.rectangle(pc_resim, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Algılama güvenini hesapla\n",
    "            guven = math.ceil((pc_kutu.conf[0] * 100)) / 100\n",
    "            print(\"Güven --->\", guven)\n",
    "\n",
    "            # Algılanan sınıfın adını al\n",
    "            sinif = int(pc_kutu.cls[0])\n",
    "            print(\"Sınıf adı -->\", sinif_isimleri[sinif])\n",
    "\n",
    "            # Algılanan nesnenin sınıf adını ve güvenini ekrana yazdır\n",
    "            metin = f\"{sinif_isimleri[sinif]}: {guven:.2f}\"\n",
    "            org = (x1, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontOlcek = 0.5\n",
    "            renk = (255, 0, 0)\n",
    "            kalinlik = 1\n",
    "\n",
    "            cv2.putText(pc_resim, metin, org, font, fontOlcek, renk, kalinlik)\n",
    "\n",
    "    # Telefon kamerasından görüntü al\n",
    "    telefon_basari, telefon_resim = telefon_kamera.read()\n",
    "\n",
    "    # Telefon kamerasından başarıyla görüntü alındı mı kontrol et\n",
    "    if telefon_basari:\n",
    "        # Görüntü boyutlarını eşitle\n",
    "        telefon_resim = cv2.resize(telefon_resim, (pc_resim.shape[1], pc_resim.shape[0]))\n",
    "\n",
    "        # Görüntüleri yatay olarak birleştir\n",
    "        birlesik_resim = cv2.hconcat([pc_resim, telefon_resim])\n",
    "\n",
    "        # Görüntüyü göster\n",
    "        cv2.imshow('Bilgisayar Kamerası', birlesik_resim)\n",
    "    else:\n",
    "        print(\"Telefon kamerasından görüntü alınamadı.\")\n",
    "\n",
    "    # 'q' tuşuna basıldığında döngüden çık\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Kameraları serbest bırak ve OpenCV pencerelerini kapat\n",
    "pc_kamera.release()\n",
    "telefon_kamera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECTION WITH PC AND WEBCAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "\n",
    "pc_kamera = cv2.VideoCapture(0)\n",
    "pc_kamera.set(3, 640)\n",
    "pc_kamera.set(4, 480)\n",
    "\n",
    "# Telefon kamerasını başlatma ve ıp ye göre bağlanma adımı \n",
    "\n",
    "# telefon_kamera_adresi = \"http://172.16.3.109:8080/video\"\n",
    "logitech_camera = cv2.VideoCapture(1,cv2.CAP_DSHOW)\n",
    "\n",
    "# hazır eğitilmiş yolo modelim\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "sinif_isimleri = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                  \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                  \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "                  \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "                  \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "                  \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "                  \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "                  \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "                  \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "                  \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Initialize variables for fps calculation\n",
    "start_time_pc = datetime.now()\n",
    "start_time_telefon = datetime.now()\n",
    "fps_pc = 0\n",
    "fps_telefon = 0\n",
    "\n",
    "while True:\n",
    "    # laptopumdan görüntü alma\n",
    "    pc_basari, pc_resim = pc_kamera.read()\n",
    "    pc_sonuclar = model(pc_resim, stream=True)\n",
    "\n",
    "    for r in pc_sonuclar:\n",
    "        pc_kutular = r.boxes\n",
    "\n",
    "        for pc_kutu in pc_kutular:\n",
    "            x1, y1, x2, y2 = pc_kutu.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            cv2.rectangle(pc_resim, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            guven = math.ceil((pc_kutu.conf[0] * 100)) / 100\n",
    "            print(\"Güven --->\", guven)\n",
    "\n",
    "            sinif = int(pc_kutu.cls[0])\n",
    "            print(\"Sınıf adı -->\", sinif_isimleri[sinif])\n",
    "\n",
    "            metin = f\"{sinif_isimleri[sinif]}: {guven:.2f}\"\n",
    "            org = (x1, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontOlcek = 0.5\n",
    "            renk = (255, 0, 0)\n",
    "            kalinlik = 1\n",
    "\n",
    "            cv2.putText(pc_resim, metin, org, font, fontOlcek, renk, kalinlik)\n",
    "\n",
    "    telefon_basari, telefon_resim = logitech_camera.read()\n",
    "\n",
    "    if telefon_basari:\n",
    "        # Görüntü boyutlarını eşitleme kısımı\n",
    "        telefon_resim = cv2.resize(telefon_resim, (pc_resim.shape[1], pc_resim.shape[0]))\n",
    "\n",
    "        # Görüntüleri birleştirme işlemi\n",
    "        birlesik_resim = cv2.hconcat([pc_resim, telefon_resim])\n",
    "\n",
    "        telefon_sonuclar = model(telefon_resim, stream=True)\n",
    "\n",
    "        for r in telefon_sonuclar:\n",
    "            telefon_kutular = r.boxes\n",
    "\n",
    "            for telefon_kutu in telefon_kutular:\n",
    "                x1, y1, x2, y2 = telefon_kutu.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                cv2.rectangle(birlesik_resim, (x1 + pc_resim.shape[1], y1), (x2 + pc_resim.shape[1], y2), (255, 0, 255), 3)\n",
    "\n",
    "                guven = math.ceil((telefon_kutu.conf[0] * 100)) / 100\n",
    "                print(\"Güven (Telefon) --->\", guven)\n",
    "\n",
    "                sinif = int(telefon_kutu.cls[0])\n",
    "                print(\"Sınıf adı (Telefon) -->\", sinif_isimleri[sinif])\n",
    "\n",
    "                metin = f\"{sinif_isimleri[sinif]}: {guven:.2f}\"\n",
    "                org = (x1 + pc_resim.shape[1], y1 - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontOlcek = 0.5\n",
    "                renk = (255, 0, 0)\n",
    "                kalinlik = 1\n",
    "\n",
    "                cv2.putText(birlesik_resim, metin, org, font, fontOlcek, renk, kalinlik)\n",
    "\n",
    "        # Calculate fps for PC camera\n",
    "        fps_pc = 1 / (datetime.now() - start_time_pc).total_seconds()\n",
    "        start_time_pc = datetime.now()\n",
    "\n",
    "        # Display fps on the PC camera window\n",
    "        cv2.putText(birlesik_resim, f\"FPS (PC): {fps_pc:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Calculate fps for Telefon camera\n",
    "        fps_telefon = 1 / (datetime.now() - start_time_telefon).total_seconds()\n",
    "        start_time_telefon = datetime.now()\n",
    "\n",
    "        # Display fps on the Telefon camera window\n",
    "        cv2.putText(birlesik_resim, f\"FPS (Logitech_camera): {fps_telefon:.2f}\", (10 + pc_resim.shape[1], 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Display the merged image\n",
    "        cv2.imshow('Bilgisayar ve Telefon Kamerası', birlesik_resim)\n",
    "    else:\n",
    "        print(\"Telefon kamerasından görüntü alınamadı.\")\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "pc_kamera.release()\n",
    "logitech_camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECTION WITH PC AND PHONE CAMERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# PC Webcam'ini başlat\n",
    "pc_kamera = cv2.VideoCapture(0)\n",
    "pc_kamera.set(3, 640)\n",
    "pc_kamera.set(4, 480)\n",
    "\n",
    "# Telefon kamerasını başlat\n",
    "telefon_kamera_adresi = \"http://172.16.3.109:8080/video\"  # Telefonunuzun IP Webcam uygulamasının sağladığı adresi kullanın\n",
    "telefon_kamera = cv2.VideoCapture(telefon_kamera_adresi)\n",
    "\n",
    "# YOLO modelini başlat\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "# Nesne sınıfları\n",
    "sinif_isimleri = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                  \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                  \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "                  \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "                  \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "                  \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "                  \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "                  \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "                  \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "                  \"teddy bear\", \"hair drier\", \"toothbrush\"]  # Sınıf isimleriniz\n",
    "\n",
    "while True:\n",
    "    # PC Webcam'inden görüntü al\n",
    "    pc_basari, pc_resim = pc_kamera.read()\n",
    "    pc_sonuclar = model(pc_resim, stream=True)\n",
    "\n",
    "    for r in pc_sonuclar:\n",
    "        pc_kutular = r.boxes\n",
    "\n",
    "        for pc_kutu in pc_kutular:\n",
    "            x1, y1, x2, y2 = pc_kutu.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Algılanan nesnenin sınırlayıcı kutusunu çiz\n",
    "            cv2.rectangle(pc_resim, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Algılama güvenini hesapla\n",
    "            guven = math.ceil((pc_kutu.conf[0] * 100)) / 100\n",
    "            print(\"guven --->\", guven)\n",
    "\n",
    "            # Algılanan sınıfın adını al\n",
    "            sinif = int(pc_kutu.cls[0])\n",
    "            print(\"Sınıf adı -->\", sinif_isimleri[sinif])\n",
    "\n",
    "            # Algılanan nesnenin sınıf adını ve güvenini ekrana yazdır\n",
    "            metin = f\"{sinif_isimleri[sinif]}: {guven:.2f}\"\n",
    "            org = (x1, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontOlcek = 0.5\n",
    "            renk = (255, 0, 0)\n",
    "            kalinlik = 1\n",
    "\n",
    "            cv2.putText(pc_resim, metin, org, font, fontOlcek, renk, kalinlik)\n",
    "\n",
    "    # Telefon kamerasından görüntü al\n",
    "    telefon_basari, telefon_resim = telefon_kamera.read()\n",
    "\n",
    "    # Telefon kamerasından başarıyla görüntü alındı mı kontrol et\n",
    "    if telefon_basari:\n",
    "        # Görüntü boyutlarını eşitle\n",
    "        telefon_resim = cv2.resize(telefon_resim, (pc_resim.shape[1], pc_resim.shape[0]))\n",
    "\n",
    "        # Görüntüleri yatay olarak birleştir\n",
    "        birlesik_resim = cv2.hconcat([pc_resim, telefon_resim])\n",
    "\n",
    "        # Telefon kamerasındaki görüntü üzerinde de nesne tespiti yap\n",
    "        telefon_sonuclar = model(telefon_resim, stream=True)\n",
    "\n",
    "        for r in telefon_sonuclar:\n",
    "            telefon_kutular = r.boxes\n",
    "\n",
    "            for telefon_kutu in telefon_kutular:\n",
    "                x1, y1, x2, y2 = telefon_kutu.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # Algılanan nesnenin sınırlayıcı kutusunu çiz\n",
    "                cv2.rectangle(birlesik_resim, (x1 + pc_resim.shape[1], y1), (x2 + pc_resim.shape[1], y2), (255, 0, 255), 3)\n",
    "\n",
    "                # Algılama güvenini hesapla\n",
    "                guven = math.ceil((telefon_kutu.conf[0] * 100)) / 100\n",
    "                print(\"Güven (Telefon) --->\", guven)\n",
    "\n",
    "                # Algılanan sınıfın adını al\n",
    "                sinif = int(telefon_kutu.cls[0])\n",
    "                print(\"Sınıf adı (Telefon) -->\", sinif_isimleri[sinif])\n",
    "\n",
    "                # Algılanan nesnenin sınıf adını ve güvenini ekrana yazdır\n",
    "                metin = f\"{sinif_isimleri[sinif]}: {guven:.2f}\"\n",
    "                org = (x1 + pc_resim.shape[1], y1 - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontOlcek = 0.5\n",
    "                renk = (255, 0, 0)\n",
    "                kalinlik = 1\n",
    "\n",
    "                cv2.putText(birlesik_resim, metin, org, font, fontOlcek, renk, kalinlik)\n",
    "\n",
    "        # Görüntüyü göster\n",
    "        cv2.imshow('Bilgisayar ve Telefon Kamerası', birlesik_resim)\n",
    "    else:\n",
    "        print(\"Telefon kamerasından görüntü alınamadı.\")\n",
    "\n",
    "    # 'q' tuşuna basıldığında döngüden çık\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Kameraları serbest bırak ve OpenCV pencerelerini kapat\n",
    "pc_kamera.release()\n",
    "telefon_kamera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THREADS WITH PHONE CAMERA AND PC CAMERA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from both cameras and perform object detection\n",
    "def capture_frames(pc_camera, phone_camera, window_name, model, class_names, target_height=480):\n",
    "    while True:\n",
    "        success_pc, frame_pc = pc_camera.read()\n",
    "        success_phone, frame_phone = phone_camera.read()\n",
    "\n",
    "        if success_pc and success_phone:\n",
    "            # Resize frames to have a consistent height\n",
    "            height_pc, width_pc, _ = frame_pc.shape\n",
    "            height_phone, width_phone, _ = frame_phone.shape\n",
    "            target_width_pc = int(target_height * (width_pc / height_pc))\n",
    "            target_width_phone = int(target_height * (width_phone / height_phone))\n",
    "\n",
    "            frame_pc = cv2.resize(frame_pc, (target_width_pc, target_height))\n",
    "            frame_phone = cv2.resize(frame_phone, (target_width_phone, target_height))\n",
    "\n",
    "            # Concatenate frames horizontally\n",
    "            combined_frame = np.concatenate((frame_pc, frame_phone), axis=1)\n",
    "\n",
    "            # Perform object detection on the combined frame\n",
    "            detect_objects(combined_frame, model, class_names, offset_x=0)\n",
    "\n",
    "            # Display the combined frame\n",
    "            cv2.imshow(window_name, combined_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# Start the PC Webcam\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Start the Phone camera\n",
    "phone_camera_address = \"http://172.16.3.109:8080/video\"  # Replace with your phone's IP Webcam address\n",
    "phone_camera = cv2.VideoCapture(phone_camera_address)\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "# Object classes\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Create a thread for capturing frames and performing object detection for both cameras\n",
    "combined_thread = threading.Thread(target=capture_frames, args=(pc_camera, phone_camera, 'Combined Cameras', yolo_model, class_names))\n",
    "\n",
    "# Start the thread\n",
    "combined_thread.start()\n",
    "\n",
    "# Wait for the thread to finish\n",
    "combined_thread.join()\n",
    "\n",
    "# Release the cameras and close OpenCV windows\n",
    "pc_camera.release()\n",
    "phone_camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THREAD WITH TWO CAMERA(WEBCAM)fps yok tek thread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from both cameras and perform object detection\n",
    "def capture_frames(pc_camera, web_camera, window_name, model, class_names, target_height=480):\n",
    "    while True:\n",
    "        success_pc, frame_pc = pc_camera.read()\n",
    "        success_web, frame_web = web_camera.read()\n",
    "\n",
    "        if success_pc and success_web:\n",
    "            # Resize frames to have a consistent height\n",
    "            height_pc, width_pc, _ = frame_pc.shape\n",
    "            height_web, width_web, _ = frame_web.shape\n",
    "            target_width_pc = int(target_height * (width_pc / height_pc))\n",
    "            target_width_web = int(target_height * (width_web / height_web))\n",
    "\n",
    "            frame_pc = cv2.resize(frame_pc, (target_width_pc, target_height))\n",
    "            frame_web = cv2.resize(frame_web, (target_width_web, target_height))\n",
    "\n",
    "            # Concatenate frames horizontally\n",
    "            combined_frame = np.concatenate((frame_pc, frame_web), axis=1)\n",
    "\n",
    "            # Perform object detection on the combined frame\n",
    "            detect_objects(combined_frame, model, class_names, offset_x=0)\n",
    "\n",
    "            # Display the combined frame\n",
    "            cv2.imshow(window_name, combined_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# Start the PC Webcam\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Start the web camera\n",
    "web_camera = cv2.VideoCapture(1,cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "# Object classes\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Create a thread for capturing frames and performing object detection for both cameras\n",
    "combined_thread = threading.Thread(target=capture_frames, args=(pc_camera, web_camera, 'Combined Cameras', yolo_model, class_names))\n",
    "\n",
    "# Start the thread\n",
    "combined_thread.start()\n",
    "\n",
    "# Wait for the thread to finish\n",
    "combined_thread.join()\n",
    "\n",
    "# Release the cameras and close OpenCV windows\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from both cameras and perform object detection\n",
    "def capture_frames(pc_camera, web_camera, window_name, model, class_names, target_height=480):\n",
    "    start_time_pc = time.time()\n",
    "    frame_count_pc = 0\n",
    "\n",
    "    start_time_web = time.time()\n",
    "    frame_count_web = 0\n",
    "\n",
    "    while True:\n",
    "        success_pc, frame_pc = pc_camera.read()\n",
    "        success_web, frame_web = web_camera.read()\n",
    "\n",
    "        if success_pc and success_web:\n",
    "            # Resize frames to have a consistent height\n",
    "            height_pc, width_pc, _ = frame_pc.shape\n",
    "            height_web, width_web, _ = frame_web.shape\n",
    "            target_width_pc = int(target_height * (width_pc / height_pc))\n",
    "            target_width_web = int(target_height * (width_web / height_web))\n",
    "\n",
    "            frame_pc = cv2.resize(frame_pc, (target_width_pc, target_height))\n",
    "            frame_web = cv2.resize(frame_web, (target_width_web, target_height))\n",
    "\n",
    "            # Concatenate frames horizontally\n",
    "            combined_frame = np.hstack((frame_pc, frame_web))\n",
    "\n",
    "            # Perform object detection on the combined frame\n",
    "            detect_objects(combined_frame, model, class_names, offset_x=0)\n",
    "\n",
    "            # Calculate and display FPS for PC Camera\n",
    "            frame_count_pc += 1\n",
    "            elapsed_time_pc = time.time() - start_time_pc\n",
    "            fps_pc = frame_count_pc / elapsed_time_pc\n",
    "            cv2.putText(combined_frame, f\"FPS PC: {fps_pc:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Calculate and display FPS for Web Camera\n",
    "            frame_count_web += 1\n",
    "            elapsed_time_web = time.time() - start_time_web\n",
    "            fps_web = frame_count_web / elapsed_time_web\n",
    "            cv2.putText(combined_frame, f\"FPS Web: {fps_web:.2f}\", (target_width_pc + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the combined frame in the window\n",
    "            cv2.imshow(window_name, combined_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# Start the PC Webcam\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Start the Web camera\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "# Object classes\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Create a thread for capturing frames and performing object detection for both cameras\n",
    "combined_thread = threading.Thread(target=capture_frames, args=(pc_camera, web_camera, 'Combined Cameras', yolo_model, class_names))\n",
    "\n",
    "# Start the thread\n",
    "combined_thread.start()\n",
    "# Wait for the thread to finish\n",
    "combined_thread.join()\n",
    "\n",
    "# Release the cameras and close OpenCV windows\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sadeleştirilmiş"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class ObjectDetector:\n",
    "    def __init__(self, model_path, class_names):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def detect_objects(self, frame, offset_x=0):\n",
    "        results = self.model(frame, stream=True)\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # Draw bounding box for the detected object\n",
    "                cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "                # Calculate detection confidence\n",
    "                confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "                # Get the class name of the detected object\n",
    "                class_id = int(box.cls[0])\n",
    "\n",
    "                # Display the class name and confidence of the detected object on the frame\n",
    "                text = f\"{self.class_names[class_id]}: {confidence:.2f}\"\n",
    "                org = (x1 + offset_x, y1 - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.5\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 1\n",
    "\n",
    "                cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "class Camera:\n",
    "    def __init__(self, camera_id, target_height=480):\n",
    "        self.camera = cv2.VideoCapture(camera_id,cv2.CAP_DSHOW)\n",
    "        self.camera.set(3, 640)\n",
    "        self.camera.set(4, target_height)\n",
    "\n",
    "    def read_frame(self):\n",
    "        success, frame = self.camera.read()\n",
    "        return success, frame\n",
    "\n",
    "    def release(self):\n",
    "        self.camera.release()\n",
    "\n",
    "class MultiCameraObjectDetection:\n",
    "    def __init__(self, pc_camera_id, web_camera_id, detector, window_name):\n",
    "        self.pc_camera = Camera(pc_camera_id)\n",
    "        self.web_camera = Camera(web_camera_id)\n",
    "        self.detector = detector\n",
    "        self.window_name = window_name\n",
    "\n",
    "    def capture_frames(self):\n",
    "        start_time_pc = time.time()\n",
    "        frame_count_pc = 0\n",
    "\n",
    "        start_time_web = time.time()\n",
    "        frame_count_web = 0\n",
    "\n",
    "        while True:\n",
    "            success_pc, frame_pc = self.pc_camera.read_frame()\n",
    "            success_web, frame_web = self.web_camera.read_frame()\n",
    "\n",
    "            if success_pc and success_web:\n",
    "                # Resize frames to have a consistent height\n",
    "                height_pc, width_pc, _ = frame_pc.shape\n",
    "                height_web, width_web, _ = frame_web.shape\n",
    "                target_width_pc = int(height_pc * (width_pc / height_pc))\n",
    "                target_width_web = int(height_web * (width_web / height_web))\n",
    "\n",
    "                frame_pc = cv2.resize(frame_pc, (target_width_pc, height_pc))\n",
    "                frame_web = cv2.resize(frame_web, (target_width_web, height_web))\n",
    "\n",
    "                # Concatenate frames horizontally\n",
    "                combined_frame = np.hstack((frame_pc, frame_web))\n",
    "\n",
    "                # Perform object detection on the combined frame\n",
    "                self.detector.detect_objects(combined_frame, offset_x=0)\n",
    "\n",
    "                # Calculate and display FPS for PC Camera\n",
    "                frame_count_pc += 1\n",
    "                elapsed_time_pc = time.time() - start_time_pc\n",
    "                fps_pc = frame_count_pc / elapsed_time_pc\n",
    "                cv2.putText(combined_frame, f\"FPS PC: {fps_pc:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                # Calculate and display FPS for Web Camera\n",
    "                frame_count_web += 1\n",
    "                elapsed_time_web = time.time() - start_time_web\n",
    "                fps_web = frame_count_web / elapsed_time_web\n",
    "                cv2.putText(combined_frame, f\"FPS Web: {fps_web:.2f}\", (target_width_pc + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                # Display the combined frame in the window\n",
    "                cv2.imshow(self.window_name, combined_frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.pc_camera.release()\n",
    "        self.web_camera.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model_path = \"yolo-Weights/yolov8n.pt\"\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "detector = ObjectDetector(yolo_model_path, class_names)\n",
    "\n",
    "# Create a thread for capturing frames and performing object detection for both cameras\n",
    "multi_cam_detector = MultiCameraObjectDetection(0, 1, detector, 'Combined Cameras')\n",
    "combined_thread = threading.Thread(target=multi_cam_detector.capture_frames)\n",
    "\n",
    "# Start the thread\n",
    "combined_thread.start()\n",
    "# Wait for the thread to finish\n",
    "combined_thread.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " iki thread ayrı ekranlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from camera and perform object detection\n",
    "def capture_frames(camera, window_name, model, class_names, target_height=480):\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        success, frame = camera.read()\n",
    "\n",
    "        if success:\n",
    "            # Resize frame to have a consistent height\n",
    "            height, width, _ = frame.shape\n",
    "            target_width = int(target_height * (width / height))\n",
    "            #target_width = 480\n",
    "            frame = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "            # Perform object detection on the frame\n",
    "            detect_objects(frame, model, class_names, offset_x=0)\n",
    "\n",
    "            # Calculate and display FPS\n",
    "            frame_count += 1\n",
    "            elapsed_time = time.time() - start_time\n",
    "            fps = frame_count / elapsed_time\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the frame in the window\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# webcamı başlatma işlemi\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Start the Web camera\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "yolo_model_2 = YOLO(\"yolo-Weights/yolov8n2.pt\")\n",
    "    \n",
    "# Object classes\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Ayrı ayrı pencereler için isimler\n",
    "window_name_pc = 'PC Camera'\n",
    "window_name_web = 'Web Camera'\n",
    "\n",
    "# Create threads for capturing frames and performing object detection for both cameras\n",
    "pc_thread = threading.Thread(target=capture_frames, args=(pc_camera, window_name_pc, yolo_model, class_names))\n",
    "web_thread = threading.Thread(target=capture_frames, args=(web_camera, window_name_web, yolo_model_2, class_names))\n",
    "\n",
    "# Start the threads\n",
    "pc_thread.start()\n",
    "web_thread.start()\n",
    "\n",
    "# Wait for the threads to finish\n",
    "pc_thread.join()\n",
    "web_thread.join()\n",
    "\n",
    "# Release the cameras and close OpenCV windows\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iki thread ayrı ekran fps iyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from camera and perform object detection\n",
    "def capture_frames(camera, window_name, model, class_names, target_height=480):\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        success, frame = camera.read()\n",
    "\n",
    "        if success:\n",
    "            # Resize frame to have a consistent height\n",
    "            height, width, _ = frame.shape\n",
    "            target_width = int(target_height * (width / height))\n",
    "            frame = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "            # Perform object detection on the frame\n",
    "            detect_objects(frame, model, class_names, offset_x=0)\n",
    "\n",
    "            # Calculate and display FPS\n",
    "            frame_count += 1\n",
    "            elapsed_time = time.time() - start_time\n",
    "            fps = frame_count / elapsed_time\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Display the frame in the window\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# Start the PC Webcam\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Start the Web camera\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "# Start the YOLO models\n",
    "yolo_model_pc = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "yolo_model_web = YOLO(\"yolo-Weights/yolov8n2.pt\")\n",
    "\n",
    "# Object classes\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Create a thread for capturing frames and performing object detection for both cameras\n",
    "pc_thread = threading.Thread(target=capture_frames, args=(pc_camera, 'PC Camera', yolo_model_pc, class_names))\n",
    "web_thread = threading.Thread(target=capture_frames, args=(web_camera, 'Web Camera', yolo_model_web, class_names))\n",
    "\n",
    "# Start the threads\n",
    "pc_thread.start()\n",
    "web_thread.start()\n",
    "\n",
    "# Wait for the threads to finish\n",
    "pc_thread.join()\n",
    "web_thread.join()\n",
    "\n",
    "# Release the cameras and close OpenCV windows\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iki thread aynı ekran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from camera and perform object detection\n",
    "def capture_frames(camera, model, class_names, offset_x, target_height=480):\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        success, frame = camera.read()\n",
    "\n",
    "        if success:\n",
    "            # Resize frame to have a consistent height\n",
    "            height, width, _ = frame.shape\n",
    "            target_width = int(target_height * (width / height))\n",
    "            frame = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "            # Perform object detection on the frame\n",
    "            detect_objects(frame, model, class_names, offset_x)\n",
    "\n",
    "            # Calculate and display FPS\n",
    "            frame_count += 1\n",
    "            elapsed_time = time.time() - start_time\n",
    "            fps = frame_count / elapsed_time\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (10 + offset_x, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            return frame\n",
    "\n",
    "# Start the PC Webcam\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Start the Web camera\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "# Start the YOLO models\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "\n",
    "# Object classes\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "\n",
    "## Function to capture frames and perform object detection\n",
    "def capture_frames_and_detect(camera, model, class_names, offset_x, frames_buffer, lock, target_height=480):\n",
    "    while True:\n",
    "        frame = capture_frames(camera, model, class_names, offset_x, target_height)\n",
    "        with lock:\n",
    "            frames_buffer[offset_x] = frame.copy()  # Ensure thread safety with a deep copy\n",
    "            # Detect objects on the frame\n",
    "            detect_objects(frames_buffer[offset_x], model, class_names, offset_x)\n",
    "\n",
    "# Create a lock and frames buffer\n",
    "lock = threading.Lock()\n",
    "frames_buffer = {}\n",
    "\n",
    "pc_thread = threading.Thread(target=capture_frames_and_detect, args=(pc_camera, yolo_model, class_names, 0, frames_buffer, lock))\n",
    "web_thread = threading.Thread(target=capture_frames_and_detect, args=(web_camera, yolo_model, class_names,640, frames_buffer, lock))\n",
    "\n",
    "# Start the threads\n",
    "pc_thread.start()\n",
    "web_thread.start()\n",
    "\n",
    "# Display frames\n",
    "while True:\n",
    "    with lock:\n",
    "        if 0 in frames_buffer and 640 in frames_buffer:\n",
    "            combined_frame = np.hstack((frames_buffer[0], frames_buffer[640]))\n",
    "            cv2.imshow('Combined Cameras', combined_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the cameras and close OpenCV windows\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0: 480x640 1 person, 102.6ms\n",
      "Speed: 4.4ms preprocess, 102.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 103.2ms\n",
      "Speed: 2.0ms preprocess, 103.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Ultralytics YOLOv8.1.9 🚀 Python-3.9.18 torch-2.2.0+cpu CPU (13th Gen Intel Core(TM) i7-1355U)\n",
      "0: 480x640 1 person, 105.0ms\n",
      "Speed: 2.0ms preprocess, 105.0ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.1ms\n",
      "Speed: 1.0ms preprocess, 92.1ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 91.1ms\n",
      "Speed: 1.0ms preprocess, 91.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 98.0ms\n",
      "Speed: 2.0ms preprocess, 98.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "0: 480x640 1 person, 95.0ms\n",
      "Speed: 1.0ms preprocess, 95.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 92.0ms\n",
      "Speed: 4.0ms preprocess, 92.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 86.2ms\n",
      "Speed: 2.0ms preprocess, 86.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 86.1ms\n",
      "Speed: 2.0ms preprocess, 86.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 124.0ms\n",
      "Speed: 2.0ms preprocess, 124.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 87.1ms\n",
      "Speed: 3.0ms preprocess, 87.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 86.0ms\n",
      "Speed: 2.0ms preprocess, 86.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.0ms\n",
      "Speed: 2.0ms preprocess, 96.0ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 2.1ms preprocess, 83.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 100.1ms\n",
      "Speed: 2.0ms preprocess, 100.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 96.1ms\n",
      "Speed: 3.0ms preprocess, 96.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 90.3ms\n",
      "Speed: 2.0ms preprocess, 90.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 90.5ms\n",
      "Speed: 2.0ms preprocess, 90.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.0ms\n",
      "Speed: 3.0ms preprocess, 94.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 89.0ms\n",
      "Speed: 2.0ms preprocess, 89.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 85.1ms\n",
      "Speed: 2.0ms preprocess, 85.1ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.6ms\n",
      "Speed: 3.0ms preprocess, 96.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.2ms\n",
      "Speed: 3.0ms preprocess, 84.2ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 85.1ms\n",
      "Speed: 2.0ms preprocess, 85.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 87.8ms\n",
      "Speed: 3.0ms preprocess, 87.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.1ms\n",
      "Speed: 4.0ms preprocess, 94.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 2.0ms preprocess, 83.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 85.8ms\n",
      "Speed: 2.0ms preprocess, 85.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 101.1ms\n",
      "Speed: 3.0ms preprocess, 101.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 87.0ms\n",
      "Speed: 5.0ms preprocess, 87.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 89.0ms\n",
      "Speed: 2.0ms preprocess, 89.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 93.0ms\n",
      "Speed: 2.0ms preprocess, 93.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.5ms\n",
      "Speed: 2.0ms preprocess, 96.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.4ms\n",
      "Speed: 4.0ms preprocess, 89.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 87.1ms\n",
      "Speed: 2.0ms preprocess, 87.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.2ms\n",
      "Speed: 2.0ms preprocess, 96.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.5ms\n",
      "Speed: 3.0ms preprocess, 90.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 85.5ms\n",
      "Speed: 1.0ms preprocess, 85.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 96.5ms\n",
      "Speed: 2.0ms preprocess, 96.5ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.7ms\n",
      "Speed: 1.0ms preprocess, 95.7ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.5ms\n",
      "Speed: 2.0ms preprocess, 90.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 82.1ms\n",
      "Speed: 2.0ms preprocess, 82.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 91.5ms\n",
      "Speed: 4.0ms preprocess, 91.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.5ms\n",
      "Speed: 2.0ms preprocess, 85.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 88.5ms\n",
      "Speed: 2.0ms preprocess, 88.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 93.6ms\n",
      "Speed: 1.2ms preprocess, 93.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.5ms\n",
      "Speed: 3.0ms preprocess, 95.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 91.0ms\n",
      "Speed: 3.0ms preprocess, 91.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 87.0ms\n",
      "Speed: 2.0ms preprocess, 87.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 90.0ms\n",
      "Speed: 2.0ms preprocess, 90.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 97.0ms\n",
      "Speed: 2.0ms preprocess, 97.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.3ms\n",
      "Speed: 3.0ms preprocess, 89.3ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 87.9ms\n",
      "Speed: 2.0ms preprocess, 87.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 3.0ms preprocess, 83.1ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 91.3ms\n",
      "Speed: 2.0ms preprocess, 91.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.2ms\n",
      "Speed: 4.2ms preprocess, 93.2ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 87.5ms\n",
      "Speed: 2.0ms preprocess, 87.5ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 86.0ms\n",
      "Speed: 2.0ms preprocess, 86.0ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.8ms\n",
      "Speed: 3.0ms preprocess, 94.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.5ms\n",
      "Speed: 2.0ms preprocess, 90.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 1.0ms preprocess, 85.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 98.1ms\n",
      "Speed: 2.0ms preprocess, 98.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.0ms\n",
      "Speed: 3.0ms preprocess, 95.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.1ms\n",
      "Speed: 3.0ms preprocess, 90.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 86.0ms\n",
      "Speed: 2.0ms preprocess, 86.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 92.0ms\n",
      "Speed: 2.0ms preprocess, 92.0ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.4ms\n",
      "Speed: 2.0ms preprocess, 93.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.5ms\n",
      "Speed: 3.0ms preprocess, 83.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 87.1ms\n",
      "Speed: 2.0ms preprocess, 87.1ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 87.0ms\n",
      "Speed: 2.0ms preprocess, 87.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.1ms\n",
      "Speed: 3.0ms preprocess, 94.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 88.6ms\n",
      "Speed: 2.0ms preprocess, 88.6ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 84.5ms\n",
      "Speed: 2.0ms preprocess, 84.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 84.1ms\n",
      "Speed: 2.0ms preprocess, 84.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.0ms\n",
      "Speed: 2.0ms preprocess, 96.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 88.1ms\n",
      "Speed: 2.0ms preprocess, 88.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 86.0ms\n",
      "Speed: 2.0ms preprocess, 86.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.2ms\n",
      "Speed: 1.0ms preprocess, 96.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 3.0ms preprocess, 83.1ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 85.1ms\n",
      "Speed: 1.0ms preprocess, 85.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.1ms\n",
      "Speed: 3.0ms preprocess, 95.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.1ms\n",
      "Speed: 3.0ms preprocess, 83.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 88.0ms\n",
      "Speed: 2.0ms preprocess, 88.0ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 93.9ms\n",
      "Speed: 1.0ms preprocess, 93.9ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 96.0ms\n",
      "Speed: 2.0ms preprocess, 96.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 88.1ms\n",
      "Speed: 3.0ms preprocess, 88.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 89.0ms\n",
      "Speed: 1.0ms preprocess, 89.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 104.3ms\n",
      "Speed: 2.1ms preprocess, 104.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 95.0ms\n",
      "Speed: 2.0ms preprocess, 95.0ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 5.0ms preprocess, 85.0ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 88.0ms\n",
      "Speed: 2.7ms preprocess, 88.0ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 84.7ms\n",
      "Speed: 1.0ms preprocess, 84.7ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 88.5ms\n",
      "Speed: 3.0ms preprocess, 88.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 1 person, 75.2ms\n",
      "Speed: 0.0ms preprocess, 75.2ms inference, 16.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.0ms\n",
      "Speed: 0.0ms preprocess, 75.0ms inference, 16.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from camera and perform object detection\n",
    "def capture_frames(camera, model, class_names, offset_x, target_height=480):\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        frame_count = 0\n",
    "\n",
    "        success, frame = camera.read()\n",
    "\n",
    "        if success:\n",
    "            # Resize frame to have a consistent height\n",
    "            height, width, _ = frame.shape\n",
    "            target_width = int(target_height * (width / height))\n",
    "            frame = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "            # Perform object detection on the frame\n",
    "            detect_objects(frame, model, class_names, offset_x)\n",
    "\n",
    "            # Calculate and display FPS\n",
    "            frame_count += 1\n",
    "            elapsed_time = time.time() - start_time\n",
    "            fps = frame_count / elapsed_time\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (10 + offset_x, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            yield frame\n",
    "\n",
    "# Start the PC Webcam\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Start the Web camera\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "# Start the YOLO models\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "# Object classes\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "\n",
    "## Function to capture frames and perform object detection\n",
    "def capture_frames_and_detect(camera, model, class_names, offset_x, frames_buffer, lock, target_height=480):\n",
    "    for frame in capture_frames(camera, model, class_names, offset_x, target_height):\n",
    "        with lock:\n",
    "            frames_buffer[offset_x] = frame.copy()  # Ensure thread safety with a deep copy\n",
    "            # Detect objects on the frame\n",
    "            detect_objects(frames_buffer[offset_x], model, class_names, offset_x)\n",
    "\n",
    "# Create a lock and frames buffer\n",
    "lock = threading.Lock()\n",
    "frames_buffer = {}\n",
    "\n",
    "pc_thread = threading.Thread(target=capture_frames_and_detect, args=(pc_camera, yolo_model, class_names, 0, frames_buffer, lock))\n",
    "web_thread = threading.Thread(target=capture_frames_and_detect, args=(web_camera, yolo_model, class_names, 640, frames_buffer, lock))\n",
    "\n",
    "# Start the threads\n",
    "pc_thread.start()\n",
    "web_thread.start()\n",
    "\n",
    "# Display frames\n",
    "while True:\n",
    "    with lock:\n",
    "        if 0 in frames_buffer and 640 in frames_buffer:\n",
    "            combined_frame = np.hstack((frames_buffer[0], frames_buffer[640]))\n",
    "            cv2.imshow('Combined Cameras', combined_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the cameras and close OpenCV windows\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 pencere "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            \n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "       \n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "def capture_frames(pc_camera, web_camera,phone_camera , window_name, model, class_names, target_height=480):\n",
    "    start_time_pc = time.time()\n",
    "    frame_count_pc = 0\n",
    "\n",
    "    start_time_web = time.time()\n",
    "    frame_count_web = 0\n",
    "    \n",
    "    start_time_phone = time.time()\n",
    "    frame_count_phone = 0\n",
    "\n",
    "    while True:\n",
    "        success_pc, frame_pc = pc_camera.read()\n",
    "        success_web, frame_web = web_camera.read()\n",
    "        success_phone_camera, frame_phone = phone_camera.read()\n",
    "\n",
    "        if success_pc and success_web and success_phone_camera:\n",
    "            \n",
    "            height_pc, width_pc, _ = frame_pc.shape\n",
    "            height_web, width_web, _ = frame_web.shape\n",
    "            height_phone,with_phone,_ = frame_phone.shape\n",
    "            \n",
    "            \n",
    "            target_width_pc = int(target_height * (width_pc / height_pc))\n",
    "            target_width_web = int(target_height * (width_web / height_web))\n",
    "            target_width_phone= int(target_height * (with_phone / height_phone))\n",
    "            \n",
    "            frame_pc = cv2.resize(frame_pc, (target_width_pc, target_height))\n",
    "            frame_web = cv2.resize(frame_web, (target_width_web, target_height))\n",
    "            frame_phone= cv2.resize(frame_phone, (target_width_phone, target_height))\n",
    "\n",
    "        \n",
    "            combined_frame = np.hstack((frame_pc, frame_web,frame_phone))\n",
    "\n",
    "            detect_objects(combined_frame, model, class_names, offset_x=0)\n",
    "\n",
    "          \n",
    "            frame_count_pc += 1\n",
    "            elapsed_time_pc = time.time() - start_time_pc\n",
    "            fps_pc = frame_count_pc / elapsed_time_pc\n",
    "            cv2.putText(combined_frame, f\"FPS PC: {fps_pc:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            frame_count_web += 1\n",
    "            elapsed_time_web = time.time() - start_time_web\n",
    "            fps_web = frame_count_web / elapsed_time_web\n",
    "            cv2.putText(combined_frame, f\"FPS Web: {fps_web:.2f}\", (target_width_pc + 10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "            frame_count_phone += 1\n",
    "            elapsed_time_phone = time.time() - start_time_phone\n",
    "            fps_phone = frame_count_phone / elapsed_time_phone\n",
    "            cv2.putText(combined_frame, f\"FPS PHONE: {fps_phone:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "            combined_frame=cv2.resize(combined_frame, (1920, 1080))\n",
    "            cv2.imshow(window_name, combined_frame)\n",
    "            #cv2.resizeWindow(window_name, 800, 600, combined_frame)\n",
    "            #cv2.imshow(window_name, combined_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# Laptop kamera başlatma işlemi\n",
    "pc_camera = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "pc_camera.set(3, 640)\n",
    "pc_camera.set(4, 480)\n",
    "\n",
    "# Web kamera başlatma işlemi\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "web_camera.set(3, 640)\n",
    "web_camera.set(4, 480)\n",
    "\n",
    "# telefon kamerasını başlatmak için\n",
    "Phone_Camera_Adress = \"http://172.16.3.109:8080/video\" \n",
    "phone_camera= cv2.VideoCapture(Phone_Camera_Adress) #Bekleme süresini azaltmak için kullanılır.\n",
    "phone_camera.set(3, 640)\n",
    "phone_camera.set(4, 480)\n",
    "\n",
    "#Hazır eğitilmiş Yolo modelimi Başlatma işlemi.\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "    \n",
    "\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "\n",
    "combined_thread = threading.Thread(target=capture_frames, args=(pc_camera, web_camera,phone_camera ,'Combined Cameras', yolo_model, class_names))\n",
    "\n",
    "\n",
    "combined_thread.start()\n",
    "\n",
    "\n",
    "combined_thread.join()\n",
    "\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "phone_camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 pencere ayrı ayrı threadli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from camera and perform object detection\n",
    "def capture_frames(camera, window_name, model, class_names, target_height=480):\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        success, frame = camera.read()\n",
    "\n",
    "        if success:\n",
    "            # Resize frame to have a consistent height\n",
    "            height, width, _ = frame.shape\n",
    "            target_width = int(target_height * (width / height))\n",
    "            frame = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "            # Perform object detection on the frame\n",
    "            detect_objects(frame, model, class_names, offset_x=0)\n",
    "\n",
    "            #fps\n",
    "            frame_count += 1\n",
    "            elapsed_time = time.time() - start_time\n",
    "            fps = frame_count / elapsed_time\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "\n",
    "            # Display the frame in the window\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    camera.release()\n",
    "\n",
    "# webcamı başlatma işlemi\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Start the Web camera\n",
    "web_camera = cv2.VideoCapture(1,cv2.CAP_DSHOW)\n",
    "\n",
    "# Start phone camera\n",
    "phone_camera_address = \"http://172.16.3.109:8080/video\"\n",
    "phone_camera = cv2.VideoCapture(phone_camera_address)\n",
    "\n",
    "# Start the YOLO models\n",
    "yolo_model_pc = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "yolo_model_web = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "yolo_model_phone = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "# Object classes\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Ayrı ayrı pencereler için isimler\n",
    "window_name_pc = 'PC Camera'\n",
    "window_name_web = 'Web Camera'\n",
    "window_name_phone = 'Phone Camera'\n",
    "\n",
    "# Create threads for capturing frames and performing object detection for each camera\n",
    "pc_thread = threading.Thread(target=capture_frames, args=(pc_camera, window_name_pc, yolo_model_pc, class_names))\n",
    "web_thread = threading.Thread(target=capture_frames, args=(web_camera, window_name_web, yolo_model_web, class_names))\n",
    "phone_thread = threading.Thread(target=capture_frames, args=(phone_camera, window_name_phone, yolo_model_phone, class_names))\n",
    "\n",
    "# Start the threads\n",
    "pc_thread.start()\n",
    "web_thread.start()\n",
    "phone_thread.start()\n",
    "\n",
    "# Wait for the threads to finish\n",
    "pc_thread.join()\n",
    "web_thread.join()\n",
    "phone_thread.join()\n",
    "\n",
    "# Release the cameras and close OpenCV windows\n",
    "pc_camera.release()\n",
    "web_camera.release()\n",
    "phone_camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 pencere tek thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from camera and perform object detection\n",
    "def capture_frames(cameras, window_names, model, class_names, target_height=480):\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        frames = []\n",
    "        for camera in cameras:\n",
    "            success, frame = camera.read()\n",
    "            if success:\n",
    "                # Resize frame to have a consistent height\n",
    "                height, width, _ = frame.shape\n",
    "                target_width = int(target_height * (width / height))\n",
    "                frame = cv2.resize(frame, (target_width, target_height))\n",
    "                frames.append(frame)\n",
    "\n",
    "        # Perform object detection on each frame\n",
    "        for frame, window_name in zip(frames, window_names):\n",
    "            detect_objects(frame, model, class_names)\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        # fps\n",
    "        frame_count += 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        fps = frame_count / elapsed_time\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    for camera in cameras:\n",
    "        camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Start the YOLO models\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Start the camera threads\n",
    "def start_camera_thread(cameras, window_names):\n",
    "    capture_thread = threading.Thread(target=capture_frames, args=(cameras, window_names, yolo_model, class_names))\n",
    "    capture_thread.start()\n",
    "    return capture_thread\n",
    "\n",
    "# Open cameras\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "phone_camera_address = \"http://172.16.3.109:8080/video\"\n",
    "phone_camera = cv2.VideoCapture(phone_camera_address)\n",
    "\n",
    "# Window names\n",
    "window_names = ['PC Camera', 'Web Camera', 'Phone Camera']\n",
    "\n",
    "# Start the camera thread\n",
    "camera_thread = start_camera_thread([pc_camera, web_camera, phone_camera], window_names)\n",
    "\n",
    "# Wait for the thread to finish\n",
    "camera_thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Function: Perform object detection on a specific frame\n",
    "def detect_objects(frame, model, class_names, offset_x=0):\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw bounding box for the detected object\n",
    "            cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # Calculate detection confidence\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "            # Get the class name of the detected object\n",
    "            class_id = int(box.cls[0])\n",
    "\n",
    "            # Display the class name and confidence of the detected object on the frame\n",
    "            text = f\"{class_names[class_id]}: {confidence:.2f}\"\n",
    "            org = (x1 + offset_x, y1 - 10)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 1\n",
    "\n",
    "            cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "# Function: Read frames from camera and perform object detection\n",
    "def capture_frames(cameras, window_names, model, class_names, target_height=480):\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        frames = []\n",
    "        for camera in cameras:\n",
    "            success, frame = camera.read()\n",
    "            if success:\n",
    "                # Resize frame to have a consistent height\n",
    "                height, width, _ = frame.shape\n",
    "                target_width = int(target_height * (width / height))\n",
    "                frame = cv2.resize(frame, (target_width, target_height))\n",
    "                frames.append(frame)\n",
    "\n",
    "        # Perform object detection on each frame\n",
    "        for frame, window_name in zip(frames, window_names):\n",
    "            detect_objects(frame, model, class_names)\n",
    "            # fps\n",
    "            frame_count += 1\n",
    "            elapsed_time = time.time() - start_time\n",
    "            fps = frame_count / elapsed_time\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    for camera in cameras:\n",
    "        camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Start the YOLO models\n",
    "yolo_model = YOLO(\"yolo-Weights/yolov8n.pt\")\n",
    "\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Start the camera threads\n",
    "def start_camera_thread(cameras, window_names):\n",
    "    capture_thread = threading.Thread(target=capture_frames, args=(cameras, window_names, yolo_model, class_names))\n",
    "    capture_thread.start()\n",
    "    return capture_thread\n",
    "\n",
    "# Open cameras\n",
    "pc_camera = cv2.VideoCapture(0)\n",
    "web_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "phone_camera_address = \"http://172.16.3.109:8080/video\"\n",
    "phone_camera = cv2.VideoCapture(phone_camera_address)\n",
    "\n",
    "# Window names\n",
    "window_names = ['PC Camera', 'Web Camera', 'Phone Camera']\n",
    "\n",
    "# Start the camera thread\n",
    "camera_thread = start_camera_thread([pc_camera, web_camera, phone_camera], window_names)\n",
    "\n",
    "# Wait for the thread to finish\n",
    "camera_thread.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "herbir kamera için thread(pc webcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class ObjectDetector:\n",
    "    def __init__(self, model_path, class_names):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def detect_objects(self, frame, offset_x=0):\n",
    "        results = self.model(frame, stream=True)\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "                # Draw bounding box for the detected object\n",
    "                cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "                # Calculate detection confidence\n",
    "                confidence = float(box.conf[0])\n",
    "\n",
    "                # Get the class name of the detected object\n",
    "                class_id = int(box.cls[0])\n",
    "\n",
    "                # Display the class name and confidence of the detected object on the frame\n",
    "                text = f\"{self.class_names[class_id]}: {confidence:.2f}\"\n",
    "                org = (x1 + offset_x, y1 - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.5\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 1\n",
    "\n",
    "                cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "class Camera:\n",
    "    def __init__(self, camera_id, target_height=480):\n",
    "        self.camera = cv2.VideoCapture(camera_id, cv2.CAP_DSHOW)\n",
    "        if not self.camera.isOpened():\n",
    "            raise ValueError(f\"Could not open camera with ID {camera_id}\")\n",
    "        self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, target_height)\n",
    "\n",
    "    def read_frame(self):\n",
    "        success, frame = self.camera.read()\n",
    "        return success, frame\n",
    "\n",
    "    def release(self):\n",
    "        self.camera.release()\n",
    "\n",
    "class MultiCameraObjectDetection:\n",
    "    def __init__(self, pc_camera_id, web_camera_id, detector, window_name):\n",
    "        self.pc_camera = Camera(pc_camera_id)\n",
    "        self.web_camera = Camera(web_camera_id)\n",
    "        self.detector = detector\n",
    "        self.window_name = window_name\n",
    "\n",
    "    def capture_pc_frames(self):\n",
    "        start_time_pc = time.time()\n",
    "        frame_count_pc = 0\n",
    "\n",
    "        while True:\n",
    "            success_pc, frame_pc = self.pc_camera.read_frame()\n",
    "\n",
    "            if success_pc:\n",
    "                frame_pc = cv2.resize(frame_pc, (640, 480))  # Resize the frame\n",
    "\n",
    "                self.detector.detect_objects(frame_pc, offset_x=0)\n",
    "\n",
    "                frame_count_pc += 1\n",
    "                elapsed_time_pc = time.time() - start_time_pc\n",
    "                fps_pc = frame_count_pc / elapsed_time_pc\n",
    "                cv2.putText(frame_pc, f\"FPS PC: {fps_pc:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                cv2.imshow(self.window_name + \" PC\", frame_pc)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.pc_camera.release()\n",
    "\n",
    "    def capture_web_frames(self):\n",
    "        start_time_web = time.time()\n",
    "        frame_count_web = 0\n",
    "\n",
    "        while True:\n",
    "            success_web, frame_web = self.web_camera.read_frame()\n",
    "\n",
    "            if success_web:\n",
    "                frame_web = cv2.resize(frame_web, (640, 480))  # Resize the frame\n",
    "\n",
    "                self.detector.detect_objects(frame_web, offset_x=0)\n",
    "\n",
    "                frame_count_web += 1\n",
    "                elapsed_time_web = time.time() - start_time_web\n",
    "                fps_web = frame_count_web / elapsed_time_web\n",
    "                cv2.putText(frame_web, f\"FPS Web: {fps_web:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                cv2.imshow(self.window_name + \" Web\", frame_web)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.web_camera.release()\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model_path = \"yolo-Weights/yolov8n.pt\"\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "detector = ObjectDetector(yolo_model_path, class_names)\n",
    "\n",
    "# Create threads for capturing frames and performing object detection for both cameras\n",
    "multi_cam_detector = MultiCameraObjectDetection(0, 1, detector, ' Camera')\n",
    "pc_thread = threading.Thread(target=multi_cam_detector.capture_pc_frames)\n",
    "web_thread = threading.Thread(target=multi_cam_detector.capture_web_frames)\n",
    "\n",
    "# Start the threads\n",
    "pc_thread.start()\n",
    "web_thread.start()\n",
    "\n",
    "# Wait for the threads to finish\n",
    "pc_thread.join()\n",
    "web_thread.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pencereler sırasıyla açılıyor fps yüksek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class ObjectDetector:\n",
    "    def __init__(self, model_path, class_names):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def detect_objects(self, frame, offset_x=0):\n",
    "        results = self.model(frame, stream=True)\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # Draw bounding box for the detected object\n",
    "                cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "                # Calculate detection confidence\n",
    "                confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "                # Get the class name of the detected object\n",
    "                class_id = int(box.cls[0])\n",
    "\n",
    "                # Display the class name and confidence of the detected object on the frame\n",
    "                text = f\"{self.class_names[class_id]}: {confidence:.2f}\"\n",
    "                org = (x1 + offset_x, y1 - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.5\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 1\n",
    "\n",
    "                cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "class Camera:\n",
    "    def __init__(self, camera_id, target_height=480):\n",
    "        self.camera = cv2.VideoCapture(camera_id,cv2.CAP_DSHOW)\n",
    "        if not self.camera.isOpened():\n",
    "            raise ValueError(f\"Could not open camera with ID {camera_id}\")\n",
    "        self.camera.set(3, 640)\n",
    "        self.camera.set(4, target_height)\n",
    "\n",
    "    def read_frame(self):\n",
    "        success, frame = self.camera.read()\n",
    "        return success, frame\n",
    "\n",
    "    def release(self):\n",
    "        self.camera.release()\n",
    "\n",
    "class MultiCameraObjectDetection:\n",
    "    def __init__(self, pc_camera_id, web_camera_id, detector, window_name):\n",
    "        self.pc_camera = Camera(pc_camera_id)\n",
    "        self.web_camera = Camera(web_camera_id)\n",
    "        self.detector = detector\n",
    "        self.window_name = window_name\n",
    "\n",
    "    def capture_pc_frames(self):\n",
    "        start_time_pc = time.time()\n",
    "        frame_count_pc = 0\n",
    "\n",
    "        while True:\n",
    "            success_pc, frame_pc = self.pc_camera.read_frame()\n",
    "\n",
    "            if success_pc:\n",
    "                height_pc, width_pc, _ = frame_pc.shape\n",
    "                target_width_pc = int(height_pc * (width_pc / height_pc))\n",
    "                frame_pc = cv2.resize(frame_pc, (target_width_pc, height_pc))\n",
    "\n",
    "                self.detector.detect_objects(frame_pc, offset_x=0)\n",
    "\n",
    "                frame_count_pc += 1\n",
    "                elapsed_time_pc = time.time() - start_time_pc\n",
    "                fps_pc = frame_count_pc / elapsed_time_pc\n",
    "                cv2.putText(frame_pc, f\"FPS PC: {fps_pc:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                cv2.imshow(self.window_name + \" PC\", frame_pc)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.pc_camera.release()\n",
    "\n",
    "    def capture_web_frames(self):\n",
    "        start_time_web = time.time()\n",
    "        frame_count_web = 0\n",
    "\n",
    "        while True:\n",
    "            success_web, frame_web = self.web_camera.read_frame()\n",
    "\n",
    "            if success_web:\n",
    "                height_web, width_web, _ = frame_web.shape\n",
    "                target_width_web = int(height_web * (width_web / height_web))\n",
    "                frame_web = cv2.resize(frame_web, (target_width_web, height_web))\n",
    "\n",
    "                self.detector.detect_objects(frame_web, offset_x=0)\n",
    "\n",
    "                frame_count_web += 1\n",
    "                elapsed_time_web = time.time() - start_time_web\n",
    "                fps_web = frame_count_web / elapsed_time_web\n",
    "                cv2.putText(frame_web, f\"FPS Web: {fps_web:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                cv2.imshow(self.window_name + \" Web\", frame_web)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.web_camera.release()\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model_path = \"yolo-Weights/yolov8n.pt\"\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "detector = ObjectDetector(yolo_model_path, class_names)\n",
    "\n",
    "# Create multi-camera object detection instance\n",
    "multi_cam_detector = MultiCameraObjectDetection(0, 1, detector, 'Combined Cameras')\n",
    "\n",
    "# Start the threads for capturing frames and performing object detection\n",
    "pc_thread = threading.Thread(target=MultiCameraObjectDetection(0, 1, detector, 'Combined Cameras').capture_pc_frames)\n",
    "web_thread = threading.Thread(target=MultiCameraObjectDetection(0, 1, detector, 'Combined Cameras').capture_web_frames)\n",
    "\n",
    "pc_thread.start()\n",
    "web_thread.start()\n",
    "\n",
    "pc_thread.join()\n",
    "web_thread.join()\n",
    "\n",
    "#multi_cam_detector.capture_pc_frames()\n",
    "#multi_cam_detector.capture_web_frames()\n",
    "\n",
    "# Release resources\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**************ANOTHER WAY********* 2 thread ayrı ekran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class ObjectDetector:\n",
    "    def __init__(self, model_path, class_names):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def detect_objects(self, frame, offset_x=0):\n",
    "        results = self.model(frame, stream=True)\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # Draw bounding box for the detected object\n",
    "                cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "                # Calculate detection confidence\n",
    "                confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "                # Get the class name of the detected object\n",
    "                class_id = int(box.cls[0])\n",
    "\n",
    "                # Display the class name and confidence of the detected object on the frame\n",
    "                text = f\"{self.class_names[class_id]}: {confidence:.2f}\"\n",
    "                org = (x1 + offset_x, y1 - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.5\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 1\n",
    "\n",
    "                cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "class Camera:\n",
    "    def __init__(self, camera_id, target_height=480):\n",
    "        self.camera = cv2.VideoCapture(camera_id)\n",
    "        if not self.camera.isOpened():\n",
    "            raise ValueError(f\"Could not open camera with ID {camera_id}\")\n",
    "        self.camera.set(3, 640)\n",
    "        self.camera.set(4, target_height)\n",
    "\n",
    "    def read_frame(self):\n",
    "        success, frame = self.camera.read()\n",
    "        return success, frame\n",
    "\n",
    "    def release(self):\n",
    "        self.camera.release()\n",
    "\n",
    "def capture_frames(camera, detector, offset_x, window_name):\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        success, frame = camera.read_frame()\n",
    "\n",
    "        if success:\n",
    "            height, width, _ = frame.shape\n",
    "            target_width = int(height * (width / height))\n",
    "            frame = cv2.resize(frame, (target_width, height))\n",
    "\n",
    "            detector.detect_objects(frame, offset_x=offset_x)\n",
    "\n",
    "            frame_count += 1\n",
    "            elapsed_time = time.time() - start_time\n",
    "            fps = frame_count / elapsed_time\n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    camera.release()\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model_path = \"yolo-Weights/yolov8n.pt\"\n",
    "yolo_model_path2 = \"yolo-Weights/yolov8n2.pt\"\n",
    "\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "detector = ObjectDetector(yolo_model_path, class_names)\n",
    "detector1=ObjectDetector(yolo_model_path2, class_names)\n",
    "\n",
    "# Create camera objects\n",
    "pc_camera = Camera(0)\n",
    "web_camera = Camera(1,cv2.CAP_DSHOW)\n",
    "\n",
    "# Create thread pool executor\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    executor.submit(capture_frames, pc_camera, detector, offset_x=0, window_name='PC Camera')\n",
    "    executor.submit(capture_frames, web_camera, detector1, offset_x=0, window_name='Web Camera')\n",
    "\n",
    "# Wait for the threads to finish\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diğer yol tek thread iki ekran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class ObjectDetector:\n",
    "    def __init__(self, model_path, class_names):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.class_names = class_names\n",
    "\n",
    "    def detect_objects(self, frame, offset_x=0):\n",
    "        results = self.model(frame, stream=True)\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # Draw bounding box for the detected object\n",
    "                cv2.rectangle(frame, (x1 + offset_x, y1), (x2 + offset_x, y2), (255, 0, 255), 3)\n",
    "\n",
    "                # Calculate detection confidence\n",
    "                confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "\n",
    "                # Get the class name of the detected object\n",
    "                class_id = int(box.cls[0])\n",
    "\n",
    "                # Display the class name and confidence of the detected object on the frame\n",
    "                text = f\"{self.class_names[class_id]}: {confidence:.2f}\"\n",
    "                org = (x1 + offset_x, y1 - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.5\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 1\n",
    "\n",
    "                cv2.putText(frame, text, org, font, font_scale, color, thickness)\n",
    "\n",
    "class Camera:\n",
    "    def __init__(self, camera_id, target_height=480):\n",
    "        self.camera = cv2.VideoCapture(camera_id)\n",
    "        if not self.camera.isOpened():\n",
    "            raise ValueError(f\"Could not open camera with ID {camera_id}\")\n",
    "        self.camera.set(3, 640)\n",
    "        self.camera.set(4, target_height)\n",
    "\n",
    "    def read_frame(self):\n",
    "        success, frame = self.camera.read()\n",
    "        return success, frame\n",
    "\n",
    "    def release(self):\n",
    "        self.camera.release()\n",
    "\n",
    "def capture_frames(cameras, detector, window_names):\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        frames = [camera.read_frame() for camera in cameras]\n",
    "        successes, frames = zip(*frames)\n",
    "\n",
    "        if all(successes):\n",
    "            frames_resized = [cv2.resize(frame, (640, 480)) for frame in frames]\n",
    "\n",
    "            for frame, window_name in zip(frames_resized, window_names):\n",
    "                detector.detect_objects(frame)\n",
    "                frame_count += 1\n",
    "                elapsed_time = time.time() - start_time\n",
    "                fps = frame_count / elapsed_time\n",
    "                cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                cv2.imshow(window_name, frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    for camera in cameras:\n",
    "        camera.release()\n",
    "\n",
    "# Start the YOLO model\n",
    "yolo_model_path = \"yolo-Weights/yolov8n.pt\"\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "               \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "detector = ObjectDetector(yolo_model_path, class_names)\n",
    "\n",
    "# Create camera objects\n",
    "pc_camera = Camera(0)\n",
    "web_camera = Camera(1,cv2.CAP_DSHOW)\n",
    "\n",
    "# Ayrı ayrı pencereler için isimler\n",
    "window_names = ['PC Camera', 'Web Camera']\n",
    "\n",
    "# Create thread pool executor\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    executor.submit(capture_frames, [pc_camera, web_camera], detector, window_names)\n",
    "\n",
    "# Wait for the thread to finish\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
